<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Bank Churn Prediction - Murtaza Shafiq</title>
  <link rel="stylesheet" href="styles.css">
</head>
<body>
  <div class="container">
    <a href="index.html" class="back-link">‚Üê Back to Portfolio</a>
    
    <div class="project-detail">
      <h1>Bank Churn Prediction</h1>
      
      <div class="project-meta">
        <span class="meta-item">
          <strong>Duration:</strong> 4 months
        </span>
        <span class="meta-item">
          <strong>Tools:</strong> PySpark, Databricks, Spark MLlib, Delta Lake
        </span>
        <span class="meta-item">
          <strong>Category:</strong> Big Data Analytics, MLOps
        </span>
      </div>

      <div class="project-section">
        <h2>Project Overview</h2>
        <p>Built a scalable end-to-end machine learning pipeline for predicting customer churn in a banking environment. The solution leveraged Databricks and PySpark to process large-scale customer data and deploy automated prediction workflows.</p>
      </div>

      <div class="project-section">
        <h2>Key Challenges</h2>
        <ul>
          <li>Processing and analyzing large volumes of customer transaction data</li>
          <li>Building scalable feature engineering pipelines</li>
          <li>Ensuring reproducible model training and deployment</li>
          <li>Implementing real-time scoring capabilities</li>
          <li>Managing data quality and model monitoring</li>
        </ul>
      </div>

      <div class="project-section">
        <h2>Solution Architecture</h2>
        <h3>1. Data Pipeline</h3>
        <ul>
          <li>Implemented Delta Lake for reliable data storage and versioning</li>
          <li>Created automated ETL workflows for data preprocessing</li>
          <li>Built data quality checks and validation steps</li>
          <li>Optimized data partitioning for efficient processing</li>
        </ul>

        <h3>2. Feature Engineering</h3>
        <ul>
          <li>Developed automated feature generation using Spark SQL</li>
          <li>Created temporal aggregations for transaction patterns</li>
          <li>Implemented feature selection using correlation analysis</li>
          <li>Built feature versioning and tracking system</li>
        </ul>

        <h3>3. Model Development</h3>
        <ul>
          <li>Trained Gradient Boosted Trees and Random Forest models using Spark MLlib</li>
          <li>Implemented cross-validation for hyperparameter tuning</li>
          <li>Created model evaluation pipelines with multiple metrics</li>
          <li>Built model versioning and experiment tracking</li>
        </ul>

        <h3>4. Deployment Pipeline</h3>
        <ul>
          <li>Automated model training and validation workflows</li>
          <li>Implemented model serving using Databricks MLflow</li>
          <li>Created monitoring dashboards for model performance</li>
          <li>Built alerting system for model drift detection</li>
        </ul>
      </div>

      <div class="project-section">
        <h2>Results & Impact</h2>
        <ul>
          <li>Achieved 86.3% accuracy in predicting customer churn</li>
          <li>Reduced model training and deployment time by 80%</li>
          <li>Enabled real-time scoring for millions of customers</li>
          <li>Improved feature engineering efficiency by 70%</li>
          <li>Created reproducible ML pipelines for future projects</li>
        </ul>
      </div>

      <div class="project-section">
        <h2>Technical Implementation</h2>
        <ul>
          <li>Used PySpark for distributed data processing</li>
          <li>Implemented MLflow for experiment tracking</li>
          <li>Leveraged Delta Lake for data reliability</li>
          <li>Created automated CI/CD pipelines for model deployment</li>
          <li>Built monitoring dashboards using Databricks SQL</li>
        </ul>
      </div>

      <div class="project-section">
        <h2>Key Learnings</h2>
        <ul>
          <li>Importance of scalable data processing in ML pipelines</li>
          <li>Value of automated feature engineering for large datasets</li>
          <li>Critical role of monitoring in production ML systems</li>
          <li>Benefits of standardized MLOps practices</li>
        </ul>
      </div>
    </div>
  </div>
</body>
</html> 